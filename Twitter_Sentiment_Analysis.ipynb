{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljr_8di_AMFr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iV2XiLxAMCH",
        "outputId": "76839ad5-1b81-4e5a-e339-6cf43b6020b0"
      },
      "source": [
        "\n",
        "df_train=pd.read_csv(\".../Twitter sentiment/train.csv\")\n",
        "df_test=pd.read_csv('.../Twitter sentiment/test.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "PwOYnbLHAMAJ",
        "outputId": "751c16f8-a87e-47d0-ac4c-e5fecc81661d"
      },
      "source": [
        "print(df_train.shape)\n",
        "df=df_train.append(df_test, ignore_index = True, sort = False)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(31962, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...\n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3    0.0                                bihday your majesty\n",
              "3   4    0.0  #model   i love u take with u all the time in ...\n",
              "4   5    0.0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDsJqxqeAoC3"
      },
      "source": [
        "#Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSBhI4sv_u76",
        "outputId": "94464e26-a1a0-44f3-fb7a-82fb8c087d7b"
      },
      "source": [
        "import nltk\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFSgJZvV_jeH"
      },
      "source": [
        "Step A : Converting html entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "qpI6Co9L_DpT",
        "outputId": "370b2167-38f8-4ef1-ffb8-9a97e86f0436"
      },
      "source": [
        "from html.parser import HTMLParser\n",
        "html_parser = HTMLParser()\n",
        "df['clean_tweet'] = df['tweet'].apply(lambda x: html_parser.unescape(x))\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                        clean_tweet\n",
              "0   1  ...   @user when a father is dysfunctional and is s...\n",
              "1   2  ...  @user @user thanks for #lyft credit i can't us...\n",
              "2   3  ...                                bihday your majesty\n",
              "3   4  ...  #model   i love u take with u all the time in ...\n",
              "4   5  ...             factsguide: society now    #motivation\n",
              "5   6  ...  [2/2] huge fan fare and big talking before the...\n",
              "6   7  ...   @user camping tomorrow @user @user @user @use...\n",
              "7   8  ...  the next school year is the year for exams.ð...\n",
              "8   9  ...  we won!!! love the land!!! #allin #cavs #champ...\n",
              "9  10  ...   @user @user welcome here !  i'm   it's so #gr...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDAJ0ix7C4Y-"
      },
      "source": [
        "Step B: Count of each label with percent before the data cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "octBDzBcA4w1",
        "outputId": "ce8412a6-da78-4c5c-a45d-81bd51edce83"
      },
      "source": [
        "def count_values_in_column(data,feature):\n",
        " total=data.loc[:,feature].value_counts(dropna=False)\n",
        " percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
        " return pd.concat([total,percentage],axis=1,keys=[\"Total\",\"Percentage\"])\n",
        "#Count_values for sentiment\n",
        "count_values_in_column(df,\"label\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>29720</td>\n",
              "      <td>60.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>17197</td>\n",
              "      <td>34.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>2242</td>\n",
              "      <td>4.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Total  Percentage\n",
              "0.0  29720       60.46\n",
              "NaN  17197       34.98\n",
              "1.0   2242        4.56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdGtszYIAfq3"
      },
      "source": [
        "Step C : Removing \"@user\" from all the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY2I6k5KDSGk"
      },
      "source": [
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "    return input_txt    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "VALGN8H0A4lJ",
        "outputId": "7c9369d7-a02d-4f72-9979-43b71491c94f"
      },
      "source": [
        "df['clean_tweet'] = np.vectorize(remove_pattern)(df['clean_tweet'], \"@[\\w]*\") \n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so sel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49154</th>\n",
              "      <td>49155</td>\n",
              "      <td>NaN</td>\n",
              "      <td>thought factory: left-right polarisation! #tru...</td>\n",
              "      <td>thought factory: left-right polarisation! #tru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49155</th>\n",
              "      <td>49156</td>\n",
              "      <td>NaN</td>\n",
              "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
              "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49156</th>\n",
              "      <td>49157</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
              "      <td>#hillary #campaigned today in #ohio((omg)) &amp; u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49157</th>\n",
              "      <td>49158</td>\n",
              "      <td>NaN</td>\n",
              "      <td>happy, at work conference: right mindset leads...</td>\n",
              "      <td>happy, at work conference: right mindset leads...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49158</th>\n",
              "      <td>49159</td>\n",
              "      <td>NaN</td>\n",
              "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
              "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49159 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                        clean_tweet\n",
              "0          1  ...    when a father is dysfunctional and is so sel...\n",
              "1          2  ...    thanks for #lyft credit i can't use cause th...\n",
              "2          3  ...                                bihday your majesty\n",
              "3          4  ...  #model   i love u take with u all the time in ...\n",
              "4          5  ...             factsguide: society now    #motivation\n",
              "...      ...  ...                                                ...\n",
              "49154  49155  ...  thought factory: left-right polarisation! #tru...\n",
              "49155  49156  ...  feeling like a mermaid ð #hairflip #neverre...\n",
              "49156  49157  ...  #hillary #campaigned today in #ohio((omg)) & u...\n",
              "49157  49158  ...  happy, at work conference: right mindset leads...\n",
              "49158  49159  ...  my   song \"so glad\" free download!  #shoegaze ...\n",
              "\n",
              "[49159 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlHNz89NBxkX"
      },
      "source": [
        "Step D : Replacing Numbers (integers) with space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OsOcq8Q_EAs_",
        "outputId": "5a706676-d6ab-4336-ff72-355a3daa8d54"
      },
      "source": [
        "df['clean_tweet'] = df['clean_tweet'].str.replace(\"[^a-zA-Z]\", \" \") \n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so sel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for  lyft credit i can t use cause th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide  society now     motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49154</th>\n",
              "      <td>49155</td>\n",
              "      <td>NaN</td>\n",
              "      <td>thought factory: left-right polarisation! #tru...</td>\n",
              "      <td>thought factory  left right polarisation   tru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49155</th>\n",
              "      <td>49156</td>\n",
              "      <td>NaN</td>\n",
              "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
              "      <td>feeling like a mermaid       hairflip  neverre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49156</th>\n",
              "      <td>49157</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
              "      <td>hillary  campaigned today in  ohio  omg     u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49157</th>\n",
              "      <td>49158</td>\n",
              "      <td>NaN</td>\n",
              "      <td>happy, at work conference: right mindset leads...</td>\n",
              "      <td>happy  at work conference  right mindset leads...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49158</th>\n",
              "      <td>49159</td>\n",
              "      <td>NaN</td>\n",
              "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
              "      <td>my   song  so glad  free download    shoegaze ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49159 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                        clean_tweet\n",
              "0          1  ...    when a father is dysfunctional and is so sel...\n",
              "1          2  ...    thanks for  lyft credit i can t use cause th...\n",
              "2          3  ...                                bihday your majesty\n",
              "3          4  ...   model   i love u take with u all the time in ...\n",
              "4          5  ...             factsguide  society now     motivation\n",
              "...      ...  ...                                                ...\n",
              "49154  49155  ...  thought factory  left right polarisation   tru...\n",
              "49155  49156  ...  feeling like a mermaid       hairflip  neverre...\n",
              "49156  49157  ...   hillary  campaigned today in  ohio  omg     u...\n",
              "49157  49158  ...  happy  at work conference  right mindset leads...\n",
              "49158  49159  ...  my   song  so glad  free download    shoegaze ...\n",
              "\n",
              "[49159 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HonwPiowB9zT"
      },
      "source": [
        "Step E : Removing words of length less then 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "JsBaxF_fELqA",
        "outputId": "5095e2fd-b885-4c7f-fc64-0ee88b3a70ce"
      },
      "source": [
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tidy_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father dysfunctional selfish drags kids i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks #lyft credit cause they offer wheelchai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model love take with time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>that youuu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>nina turner airwaves trying wrap herself mantl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>listening songs monday morning work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>#sikh #temple vandalised #calgary #wso condemns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>thank follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                         tidy_tweet\n",
              "0          0  ...  when father dysfunctional selfish drags kids i...\n",
              "1          0  ...  thanks #lyft credit cause they offer wheelchai...\n",
              "2          0  ...                                bihday your majesty\n",
              "3          0  ...                         #model love take with time\n",
              "4          0  ...                     factsguide society #motivation\n",
              "...      ...  ...                                                ...\n",
              "31957      0  ...                                         that youuu\n",
              "31958      0  ...  nina turner airwaves trying wrap herself mantl...\n",
              "31959      0  ...                listening songs monday morning work\n",
              "31960      1  ...    #sikh #temple vandalised #calgary #wso condemns\n",
              "31961      0  ...                                       thank follow\n",
              "\n",
              "[31962 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEufahI6C0F6"
      },
      "source": [
        "Step F : Spelling Correction - With TextBlob Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SamBm_UACzkb",
        "outputId": "39463834-2e72-4cbd-c364-3f9c1c9480c7"
      },
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = df['clean_tweet'][0:10].apply(lambda x: str(TextBlob(x).correct()))\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      when a father is dysfunctional and is so sel...\n",
              "1      thanks for  left credit i can t use cause th...\n",
              "2                                  midday your majesty\n",
              "3     model   i love u take with u all the time in ...\n",
              "4               factsguide  society now     motivation\n",
              "5          huge fan fare and big talking before the...\n",
              "6                     camping tomorrow        dandy   \n",
              "7    the next school year is the year for exam     ...\n",
              "8    we won    love the land     allen  caps  champ...\n",
              "9                welcome here    i m   it s so  gr    \n",
              "Name: clean_tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di_yeVYoCzXY"
      },
      "source": [
        "df['tweet_token'] = df['clean_tweet'].apply(lambda x: word_tokenize(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "efZNRwAqDd2_",
        "outputId": "0774a0ec-12c6-4983-e601-73fadfa3e7c1"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df['tweet_token_filtered'] = df['tweet_token'].apply(lambda x: [word for word in x if not word in stop_words])\n",
        "\n",
        "df[['tweet_token', 'tweet_token_filtered']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[thanks, for, lyft, credit, i, can, t, use, ca...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[bihday, your, majesty]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[model, i, love, u, take, with, u, all, the, t...</td>\n",
              "      <td>[model, love, u, take, u, time, ur]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[factsguide, society, now, motivation]</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[huge, fan, fare, and, big, talking, before, t...</td>\n",
              "      <td>[huge, fan, fare, big, talking, leave, chaos, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[camping, tomorrow, danny]</td>\n",
              "      <td>[camping, tomorrow, danny]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[the, next, school, year, is, the, year, for, ...</td>\n",
              "      <td>[next, school, year, year, exams, think, schoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[we, won, love, the, land, allin, cavs, champi...</td>\n",
              "      <td>[love, land, allin, cavs, champions, cleveland...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[welcome, here, i, m, it, s, so, gr]</td>\n",
              "      <td>[welcome, gr]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         tweet_token                               tweet_token_filtered\n",
              "0  [when, a, father, is, dysfunctional, and, is, ...  [father, dysfunctional, selfish, drags, kids, ...\n",
              "1  [thanks, for, lyft, credit, i, can, t, use, ca...  [thanks, lyft, credit, use, cause, offer, whee...\n",
              "2                            [bihday, your, majesty]                                  [bihday, majesty]\n",
              "3  [model, i, love, u, take, with, u, all, the, t...                [model, love, u, take, u, time, ur]\n",
              "4             [factsguide, society, now, motivation]                  [factsguide, society, motivation]\n",
              "5  [huge, fan, fare, and, big, talking, before, t...  [huge, fan, fare, big, talking, leave, chaos, ...\n",
              "6                         [camping, tomorrow, danny]                         [camping, tomorrow, danny]\n",
              "7  [the, next, school, year, is, the, year, for, ...  [next, school, year, year, exams, think, schoo...\n",
              "8  [we, won, love, the, land, allin, cavs, champi...  [love, land, allin, cavs, champions, cleveland...\n",
              "9               [welcome, here, i, m, it, s, so, gr]                                      [welcome, gr]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WtfYbzlEZcO"
      },
      "source": [
        "We will create 2 new columns\n",
        "\n",
        "*   One For Stemming\n",
        "*   Second For Lemmatization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38I85l3cGFTE"
      },
      "source": [
        "Stemming - Stemming refers to the removal of suffices, like “ing”, “ly”, “s”, etc. by a simple rule-based approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoKklPU2EZIa",
        "outputId": "1674c74f-447b-4cf3-f7bf-209cd81f037c"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemming = PorterStemmer()\n",
        "\n",
        "df['tweet_stemmed'] = df['tweet_token_filtered'].apply(lambda x: ' '.join([stemming.stem(i) for i in x]))\n",
        "df['tweet_stemmed'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        father dysfunct selfish drag kid dysfunct run\n",
              "1    thank lyft credit use caus offer wheelchair va...\n",
              "2                                       bihday majesti\n",
              "3                          model love u take u time ur\n",
              "4                              factsguid societi motiv\n",
              "5    huge fan fare big talk leav chao pay disput ge...\n",
              "6                                  camp tomorrow danni\n",
              "7    next school year year exam think school exam h...\n",
              "8    love land allin cav champion cleveland clevela...\n",
              "9                                            welcom gr\n",
              "Name: tweet_stemmed, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO483uUcHBGB"
      },
      "source": [
        "Lemmatization - Lemmatization is the process of converting a word to its base form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKDCk39cHDmL",
        "outputId": "236ec499-27a1-4985-e59a-6edde1d4caf5"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lemmatizing = WordNetLemmatizer()\n",
        "\n",
        "df['tweet_lemmatized'] = df['tweet_token_filtered'].apply(lambda x: ' '.join([lemmatizing.lemmatize(i) for i in x]))\n",
        "df['tweet_lemmatized'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    father dysfunctional selfish drag kid dysfunct...\n",
              "1    thanks lyft credit use cause offer wheelchair ...\n",
              "2                                       bihday majesty\n",
              "3                          model love u take u time ur\n",
              "4                        factsguide society motivation\n",
              "5    huge fan fare big talking leave chaos pay disp...\n",
              "6                               camping tomorrow danny\n",
              "7    next school year year exam think school exam h...\n",
              "8    love land allin cavs champion cleveland clevel...\n",
              "9                                           welcome gr\n",
              "Name: tweet_lemmatized, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gONDcNTTIPeU"
      },
      "source": [
        "Extracting Features from Cleaned Tweets\n",
        "\n",
        "\n",
        "A - Bag-of-Words Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6Hj63jWELfb",
        "outputId": "41e7e955-b3f1-42d8-dad6-89d4ccb2a9e5"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "\n",
        "\n",
        "bow_stem = bow_vectorizer.fit_transform(df['tweet_stemmed'])\n",
        "bow_stem\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49159x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 203168 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sIQlqraIntA",
        "outputId": "ed953b4d-3ee5-497c-c08c-ae7df2788d3f"
      },
      "source": [
        "bow_lemm = bow_vectorizer.fit_transform(df['tweet_lemmatized'])\n",
        "bow_lemm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49159x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 187064 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URXNIXgmI-9i"
      },
      "source": [
        "B- TF-IDF Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0hryxrHJE0-",
        "outputId": "b73be761-dcfa-4f0f-b4d1-f8608b36bcd7"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "tfidf_vectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=0.9, max_features=1000,\n",
              "                min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsY18MqNJEyC",
        "outputId": "9cd4a5cc-8cd5-4b73-bbfb-dbaed5e84e7d"
      },
      "source": [
        "tfidf_stem = tfidf_vectorizer.fit_transform(df['tweet_stemmed'])\n",
        "tfidf_stem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49159x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 203168 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhqfQ4yyJEvR",
        "outputId": "c40703a5-c0e2-49e1-f26c-4857219305cb"
      },
      "source": [
        "tfidf_lemm = tfidf_vectorizer.fit_transform(df['tweet_lemmatized'])\n",
        "tfidf_lemm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49159x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 187064 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKtAYDfZJ9EB"
      },
      "source": [
        "#Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t3bMvhdJEsb"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJeTWBVPKHff"
      },
      "source": [
        "A Building model using Bag-of-Words features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxcfZHpGJ66v",
        "outputId": "d4adce33-58ac-480b-82bf-1b26305774ae"
      },
      "source": [
        "# A.1 For columns \"combine_df['tweet_stemmed']\"\n",
        "train_bow = bow_stem[:31962,:]\n",
        "test_bow = bow_stem[31962:,:]\n",
        "\n",
        "# splitting data into training and validation set\n",
        "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, df_train['label'], random_state=42, test_size=0.3)\n",
        "\n",
        "lreg = LogisticRegression()\n",
        "lreg.fit(xtrain_bow, ytrain) # training the model\n",
        "\n",
        "prediction = lreg.predict_proba(xvalid_bow) # predicting on the validation set\n",
        "prediction_int = prediction[:,1] >= 0.3 # if prediction is greater than or equal to 0.3 than 1 else 0\n",
        "prediction_int = prediction_int.astype(np.int)\n",
        "\n",
        "A1 = f1_score(yvalid, prediction_int) # calculating f1 score\n",
        "print(A1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5529801324503311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SubsmYu5Kx6P",
        "outputId": "e05fb269-b8f8-49d0-ae36-35fdfc1283a2"
      },
      "source": [
        "train_bow = bow_lemm[:31962,:]\n",
        "test_bow = bow_lemm[31962:,:]\n",
        "\n",
        "# splitting data into training and validation set\n",
        "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, df_train['label'], random_state=42, test_size=0.3)\n",
        "\n",
        "lreg = LogisticRegression()\n",
        "lreg.fit(xtrain_bow, ytrain) # training the model\n",
        "\n",
        "prediction = lreg.predict_proba(xvalid_bow) # predicting on the validation set\n",
        "prediction_int = prediction[:,1] >= 0.3 # if prediction is greater than or equal to 0.3 than 1 else 0\n",
        "prediction_int = prediction_int.astype(np.int)\n",
        "\n",
        "A2 = f1_score(yvalid, prediction_int) # calculating f1 score\n",
        "print(A2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5376712328767123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmxVOsQgK8Xd"
      },
      "source": [
        "B Building model using TF-IDF features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL8c3OJ-Kx1V",
        "outputId": "724e837c-4dbf-480f-ce07-ec7cad09c2b0"
      },
      "source": [
        "train_tfidf = tfidf_stem[:31962,:]\n",
        "test_tfidf = tfidf_stem[31962:,:]\n",
        "\n",
        "xtrain_tfidf = train_tfidf[ytrain.index]\n",
        "xvalid_tfidf = train_tfidf[yvalid.index]\n",
        "\n",
        "lreg.fit(xtrain_tfidf, ytrain)\n",
        "\n",
        "prediction = lreg.predict_proba(xvalid_tfidf)\n",
        "prediction_int = prediction[:,1] >= 0.3\n",
        "prediction_int = prediction_int.astype(np.int)\n",
        "\n",
        "B1 = f1_score(yvalid, prediction_int) # calculating f1 score\n",
        "print(B1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.551056338028169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvRS_1a_LAUc",
        "outputId": "fb7b12c8-270e-497e-abf9-b17708af8b57"
      },
      "source": [
        "\n",
        "train_tfidf = tfidf_lemm[:31962,:]\n",
        "test_tfidf = tfidf_lemm[31962:,:]\n",
        "\n",
        "xtrain_tfidf = train_tfidf[ytrain.index]\n",
        "xvalid_tfidf = train_tfidf[yvalid.index]\n",
        "\n",
        "lreg.fit(xtrain_tfidf, ytrain)\n",
        "\n",
        "prediction = lreg.predict_proba(xvalid_tfidf)\n",
        "prediction_int = prediction[:,1] >= 0.3\n",
        "prediction_int = prediction_int.astype(np.int)\n",
        "\n",
        "B2 = f1_score(yvalid, prediction_int) # calculating f1 score\n",
        "print(B2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5415549597855227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pv4-DxjLMxR"
      },
      "source": [
        "Result of Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tPz0iV7LH_S",
        "outputId": "651e577a-a1ca-472c-a811-2a1878c9ab86"
      },
      "source": [
        "print(\"F1 - Score Chart\")\n",
        "print(\"* F1-Score - Model using Bag-of-Words features\")\n",
        "print(\"   F1-Score = \",A1,\" - For column tweets are stemmed\")\n",
        "print(\"   F1-Score = \",A2,\" - For column tweets are Lemmatized\")\n",
        "print(\"* F1-Score - Model using TF-IDF features\")\n",
        "print(\"   F1-Score = \",B1,\" - For column tweets are stemmed\")\n",
        "print(\"   F1-Score = \",B2,\" - For column tweets are Lemmatized\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 - Score Chart\n",
            "* F1-Score - Model using Bag-of-Words features\n",
            "   F1-Score =  0.5529801324503311  - For column tweets are stemmed\n",
            "   F1-Score =  0.5376712328767123  - For column tweets are Lemmatized\n",
            "* F1-Score - Model using TF-IDF features\n",
            "   F1-Score =  0.551056338028169  - For column tweets are stemmed\n",
            "   F1-Score =  0.5415549597855227  - For column tweets are Lemmatized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMPWclCSLefT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}